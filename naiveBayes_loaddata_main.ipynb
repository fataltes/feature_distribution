{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "execute_notebook : A method to load and execute another notebook in this notebook's namespace\n",
    "\n",
    "cite: http://nbviewer.jupyter.org/gist/minrk/5491090/analysis.ipynb\n",
    "\n",
    "Call it for your notebook that want to import here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "    \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)\n",
    "execute_notebook(\"distributions_fit_and_likelihood.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary packages and libraries to connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "db = 'twitterGender'\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "myDB = URL(drivername='mysql', database=db, query={ 'read_default_file' : '/home/fatal/.my.cnf' })\n",
    "engine = create_engine(name_or_url=myDB, encoding='utf8')\n",
    "#conn = engine.connect()\n",
    "\n",
    "small_val = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [\n",
    "    'zin_norm', 'zin_lognorm', 'zin_powerlaw'\n",
    "]\n",
    "kfold = 5\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate k random folds of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_kfolds(label_table_name):\n",
    "    # Load DATA from DB\n",
    "    id_labels = pd.read_sql('select group_id, label from ' + label_table_name, con=engine)\n",
    "    group_id_cnt = len(id_labels)\n",
    "    print (\"Total number of individuals: \" + str(group_id_cnt))\n",
    "\n",
    "    # generating k-folds of ids\n",
    "    #random.shuffle() works for lists\n",
    "    id_labels = id_labels.sample(frac=1)\n",
    "    train_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    test_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    label_prior_prob = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "\n",
    "    for k in range(kfold):\n",
    "        test_start = int(group_id_cnt*k/kfold)\n",
    "        test_end = int(group_id_cnt*(k+1)/kfold)\n",
    "        # Separate train and test\n",
    "        test_kth_fold = id_labels[test_start: test_end]\n",
    "        train_kth_fold = pd.concat([id_labels.iloc[0: test_start], id_labels.iloc[test_end:group_id_cnt]]) \n",
    "        total = len(train_kth_fold)\n",
    "        for l in range(labels): # For each fold, separate data with different labels\n",
    "            train_fold[k][l] = (train_kth_fold[train_kth_fold.label == l].group_id).tolist()\n",
    "            label_prior_prob[k][l] = len(train_fold[k][l])/total\n",
    "            test_fold[k][l] = (test_kth_fold[test_kth_fold.label == l].group_id).tolist()\n",
    "    return (label_prior_prob, train_fold, test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Build Naive Bayes classifier for each fold\n",
    "\n",
    " table_name: Name of the feature table\n",
    " \n",
    " ### Arguments\n",
    " * kfold: number of folds\n",
    " * labels: number of labels\n",
    " * train_fold: a k by l array. k fold of train set divided based on their labels\n",
    " \n",
    "### Returns\n",
    "params: a k by l by # of dist array. parameters of each distribution for each train set in each category of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildNaiveBayes(table_name, train_fold):\n",
    "    kfold = len(train_fold)\n",
    "    labels = len(train_fold[0])\n",
    "    params = [[{} for l in range(labels)] for k in range(kfold)]\n",
    "    defaults = [[init_default() for l in range(labels)] for k in range(kfold)]\n",
    "    cntr = 1\n",
    "    query_time = 0\n",
    "    fit_time = 0\n",
    "        \n",
    "    stime = time.time()\n",
    "    # Load list of distinct features\n",
    "    features = pd.read_sql('select feat, count(*) cnt from ' + table_name + ' group by feat', con=engine)\n",
    "    feat_cnt = len(features)\n",
    "    print(str(feat_cnt) + ' unique features' )\n",
    "    \n",
    "    # Load data, feature by feature, and set distribution parameters for each quadruple\n",
    "    # (fold, gender, feature, dist)\n",
    "    for index, eachfeat in features.iterrows():\n",
    "        feat = eachfeat.feat\n",
    "        qs = time.time()\n",
    "        feat2search = feat.replace(\"'\", \"''\").replace(\"%\", \"%%\").replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        fetch_data_query = \"select * from \" + table_name + \" where feat = '\" + feat2search + \"'\"\n",
    "        raw_df = pd.read_sql(fetch_data_query, con=engine)\n",
    "        qe = time.time()\n",
    "\n",
    "        for k in range(kfold):\n",
    "            for l in range(labels):\n",
    "                params[k][l][feat] = {}\n",
    "                train = raw_df[raw_df.group_id.isin(train_fold[k][l])].group_norm.tolist()\n",
    "                train += [0] * (len(train_fold[k][l]) - len(train))\n",
    "                train = np.asarray(train) # input of functions \"update_default\" and \"mle\" should be nparray\n",
    "                defaults[k][l] = update_default(train, defaults[k][l])\n",
    "                for dist in DISTRIBUTIONS:\n",
    "                    params[k][l][feat][dist] = mle(train, dist) # calc MLE\n",
    "                     \n",
    "        beste = time.time()\n",
    "        query_time += (qe-qs)\n",
    "        fit_time += (beste-qe)\n",
    "        print '\\r', str(cntr) + ' out of ' + str(feat_cnt) + ', ' + feat , \n",
    "        cntr += 1\n",
    "    etime = time.time()\n",
    "    print\n",
    "    print('overall time: ' + str(round(etime-stime)) + 's -> I/O time: ' + str(round(query_time)) + \\\n",
    "          's, run time: ' + str(round(fit_time)) + 's') \n",
    "\n",
    "    return params, defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Naive Bayes for all Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_naiveBayes(table_name, test_fold, label_prior_prob, params, defaults):\n",
    "    kfold = len(test_fold)\n",
    "    labels = len(test_fold[0])\n",
    "    tp = {}\n",
    "    total = 0\n",
    "    label_tp = [0] * labels\n",
    "    label_total = [0] * labels\n",
    "    # as we should have a distribution for all features in all kfolds and labels, it doesn't matter which k or l\n",
    "    # we choose to get list of all features from \n",
    "    all_feats = set(params[0][0].keys())\n",
    "    for l in range(labels):\n",
    "        label_tp[l] = {}\n",
    "        for dist in DISTRIBUTIONS:\n",
    "            tp[dist] = 0\n",
    "            label_tp[l][dist] = 0\n",
    "    group_id_cnt = 0\n",
    "    for k in range(kfold):\n",
    "        for l in range(labels):\n",
    "            group_id_cnt += len(test_fold[k][l])\n",
    "    print (\"Total number of test cases: \" + str(group_id_cnt))\n",
    "    cntr = 1\n",
    "    query_total_time = 0\n",
    "    run_time = 0\n",
    "    st = time.time()\n",
    "    for k in range(kfold):\n",
    "        for test_l in range(labels): \n",
    "            qs = time.time()\n",
    "            fetch_data_query = \"select * from \" + table_name + \\\n",
    "                \" where group_id in (\"+str(test_fold[k][test_l])[1:-1]+\")\"\n",
    "            test_df = pd.read_sql(fetch_data_query, con=engine)\n",
    "            qe = time.time()\n",
    "            query_total_time += (qe - qs)\n",
    "            for id, grp in test_df.groupby(\"group_id\"):\n",
    "                s1 = time.time()\n",
    "                zero_feats = all_feats - set(grp.feat) # select features that have'nt been used by this id\n",
    "                t3 = time.time()\n",
    "                for dist in DISTRIBUTIONS:\n",
    "                    max_prob = float(\"-inf\")\n",
    "                    best_label = -1\n",
    "                    for l in range(labels): # go through all classes to find best class as the match label\n",
    "                        label_prob = np.log(label_prior_prob[k][l])                                            \n",
    "                        t4 = time.time()\n",
    "                        for idx, row in grp.iterrows(): # go over all available features of an individual\n",
    "                            data = [row.group_norm]\n",
    "                            label_prob += np.log(pdmf(np.asarray(data) , dist, params[k][l][row.feat][dist],\\\n",
    "                                                     defaults[k][l]))\n",
    "                            \n",
    "                        t5 = time.time()\n",
    "                        for feat in zero_feats: # go over all non-available features of an individual\n",
    "                            label_prob += params[k][l][feat][dist]['logp0']\n",
    "                        t6 = time.time()\n",
    "                        if label_prob > max_prob: # choose best label with maximum probability\n",
    "                            best_label = l\n",
    "                            max_prob = label_prob\n",
    "                    # Track correct classifications as tp:True Positive\n",
    "                    if best_label == test_l:\n",
    "                        tp[dist] += 1\n",
    "                        label_tp[test_l][dist] += 1\n",
    "                e1 = time.time()\n",
    "                print '\\r' + str(cntr) + ' out of ' + str(group_id_cnt), str(round(e1-s1, 2)), \n",
    "                cntr += 1\n",
    "                # Track total number of test cases\n",
    "                total += 1\n",
    "                label_total[test_l] += 1\n",
    "            run_time += (time.time() - qe)\n",
    "    et = time.time()\n",
    "    total_time = et-st\n",
    "    print \n",
    "    print (\"overall time: \" + str(round(total_time)) + \"s -> I/O time: \" + str(round(query_total_time)) + \\\n",
    "           \"s, run time: \" + str(round(run_time)) + \"s\")\n",
    "    return (total, label_total, tp, label_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Names\n",
    "\n",
    "It's important that table_name and label_table_name be synchronized together. \n",
    "That's why I put the definition of these two tables together in one chunck.\n",
    "\n",
    "Table_name is the name of the feature table we want to analyze which can be in each of the cnty, user, or message level. Depending on the level of feature table, label_table_name should be the name of the table containing list of group_ids and labels in the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_label_table_name = \"msgs_cntiesw10u10m_cnties_gender\"\n",
    "cliwc_table_name = \"feat$cat_LIWC2007$msgs_cntiesw10u10m$cnty$16to16\"\n",
    "ctopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_cntiesw10u10m$cnty$16to16\"\n",
    "c1gram_table_name = \"feat$1gram$msgs_cntiesw10u10m$cnty$16to16$0_05\"\n",
    "\n",
    "u_label_table_name = \"msgs_cntiesw10u10m_usrs_gender\"\n",
    "uliwc_table_name = \"feat$cat_LIWC2007$msgs_cntiesw10u10m$user_id$16to16\"\n",
    "utopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_cntiesw10u10m$user_id$16to16\"\n",
    "u1gram_table_name = \"feat$1gram$msgs_cntiesw10u10m$user_id$16to16$0_01\"\n",
    "\n",
    "m_label_table_name = \"msgs_w10u10m_mr20k_msgs_gender\"\n",
    "mliwc_table_name = \"feat$cat_LIWC2007$msgs_w10u10m_mr20k$message_id$16to16\"\n",
    "mtopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_w10u10m_mr20k$message_id$16to16\"\n",
    "m1gram_table_name = \"feat$1gram$msgs_w10u10m_mr20k$message_id$16to16$0_0005\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all kfolds train and test in each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals: 872\n",
      "Total number of individuals: 9234\n",
      "Total number of individuals: 20000\n"
     ]
    }
   ],
   "source": [
    "c_label_prior_prob, c_train_fold, c_test_fold = generate_kfolds(c_label_table_name)\n",
    "\n",
    "u_label_prior_prob, u_train_fold, u_test_fold = generate_kfolds(u_label_table_name)\n",
    "\n",
    "m_label_prior_prob, m_train_fold, m_test_fold = generate_kfolds(m_label_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "LIWC, COUNTY\n",
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 2.0s -> I/O time: 1.0s, run time: 1.0s\n",
      "\n",
      "LIWC, USER\n",
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 10.0s -> I/O time: 6.0s, run time: 3.0s\n",
      "\n",
      "LIWC, MESSAGE\n",
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 7.0s -> I/O time: 3.0s, run time: 4.0s\n",
      "\n",
      "TOPICS, COUNTY\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 68.0s -> I/O time: 32.0s, run time: 33.0s\n",
      "\n",
      "TOPICS, USER\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 388.0s -> I/O time: 231.0s, run time: 107.0s\n",
      "\n",
      "TOPICS, MESSAGE\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 182.0s -> I/O time: 59.0s, run time: 117.0s\n",
      "\n",
      "1GRAM, COUNTY\n",
      "45387 unique features\n",
      "45387 out of 45387, ￣\n",
      "overall time: 783.0s -> I/O time: 169.0s, run time: 593.0s\n",
      "\n",
      "1GRAM, USER\n",
      "13879 unique features\n",
      "13879 out of 13879, ️\n",
      "overall time: 513.0s -> I/O time: 98.0s, run time: 403.0s\n",
      "\n",
      "1GRAM, MESSAGE\n",
      "2322 unique features\n",
      "2322 out of 2322, ️\n",
      "overall time: 124.0s -> I/O time: 9.0s, run time: 113.0s\n"
     ]
    }
   ],
   "source": [
    "# LIWC\n",
    "print '\\nLIWC, COUNTY'; cliwc_params, cliwc_defaults = buildNaiveBayes(cliwc_table_name, c_train_fold)\n",
    "print '\\nLIWC, USER'; uliwc_params, uliwc_defaults = buildNaiveBayes(uliwc_table_name, u_train_fold)\n",
    "print '\\nLIWC, MESSAGE'; mliwc_params, mliwc_defaults = buildNaiveBayes(mliwc_table_name, m_train_fold)\n",
    "\n",
    "# TOPICS\n",
    "print '\\nTOPICS, COUNTY'; ctopic_params, ctopic_defaults = buildNaiveBayes(ctopic_table_name, c_train_fold)\n",
    "print '\\nTOPICS, USER'; utopic_params, utopic_defaults = buildNaiveBayes(utopic_table_name, u_train_fold)\n",
    "print '\\nTOPICS, MESSAGE'; mtopic_params, mtopic_defaults = buildNaiveBayes(mtopic_table_name, m_train_fold)\n",
    "\n",
    "# 1GRAMS\n",
    "print '\\n1GRAM, COUNTY'; c1gram_params, c1gram_defaults = buildNaiveBayes(c1gram_table_name, c_train_fold)\n",
    "print '\\n1GRAM, USER'; u1gram_params, u1gram_defaults = buildNaiveBayes(u1gram_table_name, u_train_fold)\n",
    "print '\\n1GRAM, MESSAGE'; m1gram_params, m1gram_defaults = buildNaiveBayes(m1gram_table_name, m_train_fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC , COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 872\n",
      "872 out of 872 0.0\n",
      "overall time: 77.0s -> I/O time: 0.0s, run time: 76.0s\n"
     ]
    }
   ],
   "source": [
    "cliwc_tot, cliwc_ltot, cliwc_tp, cliwc_ltp = \\\n",
    "test_naiveBayes(cliwc_table_name, c_test_fold, c_label_prior_prob, cliwc_params, cliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 9234\n",
      "9233 out of 9234 0.05\n",
      "overall time: 760.0s -> I/O time: 6.0s, run time: 753.0s\n"
     ]
    }
   ],
   "source": [
    "uliwc_tot, uliwc_ltot, uliwc_tp, uliwc_ltp = \\\n",
    "test_naiveBayes(uliwc_table_name, u_test_fold, u_label_prior_prob, uliwc_params, uliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 20000\n",
      "19207 out of 20000 0.02\n",
      "overall time: 440.0s -> I/O time: 5.0s, run time: 435.0s\n"
     ]
    }
   ],
   "source": [
    "mliwc_tot, mliwc_ltot, mliwc_tp, mliwc_ltp = \\\n",
    "test_naiveBayes(mliwc_table_name, m_test_fold, m_label_prior_prob, mliwc_params, mliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'zin_lognorm': 470, 'zin_norm': 443, 'zin_powerlaw': 434} out of 872\n",
      "{'zin_lognorm': 5159, 'zin_norm': 5726, 'zin_powerlaw': 4323} out of 9233\n",
      "{'zin_lognorm': 10377, 'zin_norm': 10234, 'zin_powerlaw': 10344} out of 19207\n",
      "\n",
      "\n",
      "\n",
      "[{'zin_lognorm': 291, 'zin_norm': 260, 'zin_powerlaw': 81}, {'zin_lognorm': 179, 'zin_norm': 183, 'zin_powerlaw': 353}] out of [436, 436]\n",
      "[{'zin_lognorm': 2071, 'zin_norm': 3139, 'zin_powerlaw': 144}, {'zin_lognorm': 3088, 'zin_norm': 2587, 'zin_powerlaw': 4179}] out of [4943, 4290]\n",
      "[{'zin_lognorm': 7066, 'zin_norm': 6956, 'zin_powerlaw': 8891}, {'zin_lognorm': 3311, 'zin_norm': 3278, 'zin_powerlaw': 1453}] out of [10589, 8618]\n"
     ]
    }
   ],
   "source": [
    "print cliwc_tp, \"out of\", cliwc_tot\n",
    "print uliwc_tp, \"out of\", uliwc_tot\n",
    "print mliwc_tp, \"out of\", mliwc_tot\n",
    "print '\\n\\n'\n",
    "print cliwc_ltp, \"out of\", cliwc_ltot\n",
    "print uliwc_ltp, \"out of\", uliwc_ltot\n",
    "print mliwc_ltp, \"out of\", mliwc_ltot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of test cases: 872\n",
      "872 out of 872 2.57\n",
      "overall time: 2344.0s -> I/O time: 21.0s, run time: 2323.0s\n"
     ]
    }
   ],
   "source": [
    "ctopic_tot, ctopic_ltot, ctopic_tp, ctopic_ltp = \\\n",
    "test_naiveBayes(ctopic_table_name, c_test_fold, c_label_prior_prob, ctopic_params, ctopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 9234\n",
      "9233 out of 9234 1.67\n",
      "overall time: 22706.0s -> I/O time: 181.0s, run time: 22525.0s\n"
     ]
    }
   ],
   "source": [
    "utopic_tot, utopic_ltot, utopic_tp, utopic_ltp = \\\n",
    "test_naiveBayes(utopic_table_name, u_test_fold, u_label_prior_prob, utopic_params, utopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 20000\n",
      "19025 out of 20000 0.26\n",
      "overall time: 6701.0s -> I/O time: 50.0s, run time: 6651.0s\n"
     ]
    }
   ],
   "source": [
    "mtopic_tot, mtopic_ltot, mtopic_tp, mtopic_ltp = \\\n",
    "test_naiveBayes(mtopic_table_name, m_test_fold, m_label_prior_prob, mtopic_params, mtopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'zin_lognorm': 473, 'zin_norm': 433, 'zin_powerlaw': 446} out of 872\n",
      "{'zin_lognorm': 5334, 'zin_norm': 5972, 'zin_powerlaw': 4394} out of 9233\n",
      "{'zin_lognorm': 10337, 'zin_norm': 10163, 'zin_powerlaw': 10295} out of 19025\n",
      "\n",
      "\n",
      "\n",
      "[{'zin_lognorm': 306, 'zin_norm': 277, 'zin_powerlaw': 391}, {'zin_lognorm': 167, 'zin_norm': 156, 'zin_powerlaw': 55}] out of [436, 436]\n",
      "[{'zin_lognorm': 2393, 'zin_norm': 3442, 'zin_powerlaw': 282}, {'zin_lognorm': 2941, 'zin_norm': 2530, 'zin_powerlaw': 4112}] out of [4943, 4290]\n",
      "[{'zin_lognorm': 5813, 'zin_norm': 5573, 'zin_powerlaw': 5941}, {'zin_lognorm': 4524, 'zin_norm': 4590, 'zin_powerlaw': 4354}] out of [10486, 8539]\n"
     ]
    }
   ],
   "source": [
    "print ctopic_tp, \"out of\", ctopic_tot\n",
    "print utopic_tp, \"out of\", utopic_tot\n",
    "print mtopic_tp, \"out of\", mtopic_tot\n",
    "print '\\n\\n'\n",
    "print ctopic_ltp, \"out of\", ctopic_ltot\n",
    "print utopic_ltp, \"out of\", utopic_ltot\n",
    "print mtopic_ltp, \"out of\", mtopic_ltot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1gram_tot, c1gram_ltot, c1gram_tp, c1gram_ltp = \\\n",
    "test_naiveBayes(c1gram_table_name, c_test_fold, c_label_prior_prob, c1gram_params, c1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u1gram_tot, u1gram_ltot, u1gram_tp, u1gram_ltp = \\\n",
    "test_naiveBayes(u1gram_table_name, u_test_fold, u_label_prior_prob, u1gram_params, u1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1gram_tot, m1gram_ltot, m1gram_tp, m1gram_ltp = \\\n",
    "test_naiveBayes(m1gram_table_name, m_test_fold, m_label_prior_prob, m1gram_params, m1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print c1gram_tp, \"out of\", c1gram_tot\n",
    "print u1gram_tp, u1gram_tot\n",
    "print m1gram_tp, m1gram_tot\n",
    "print '\\n\\n'\n",
    "print c1gram_ltp, c1gram_ltot\n",
    "print u1gram_ltp, u1gram_ltot\n",
    "print m1gram_ltp, m1gram_ltot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
