{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "execute_notebook : A method to load and execute another notebook in this notebook's namespace\n",
    "\n",
    "cite: http://nbviewer.jupyter.org/gist/minrk/5491090/analysis.ipynb\n",
    "\n",
    "Call it for your notebook that want to import here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "    \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)\n",
    "execute_notebook(\"distributions_fit_and_likelihood.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary packages and libraries to connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "db = 'twitterGender'\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "myDB = URL(drivername='mysql', database=db, query={ 'read_default_file' : '/home/fatal/.my.cnf' })\n",
    "engine = create_engine(name_or_url=myDB, encoding='utf8')\n",
    "#conn = engine.connect()\n",
    "\n",
    "small_val = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [\n",
    "    'zin_norm', 'zin_lognorm', 'zin_powerlaw'\n",
    "]\n",
    "kfold = 5\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate k random folds of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_kfolds(label_table_name):\n",
    "    # Load DATA from DB\n",
    "    id_labels = pd.read_sql('select group_id, label from ' + label_table_name, con=engine)\n",
    "    group_id_cnt = len(id_labels)\n",
    "    print (\"Total number of individuals: \" + str(group_id_cnt))\n",
    "\n",
    "    # generating k-folds of ids\n",
    "    #random.shuffle() works for lists\n",
    "    id_labels = id_labels.sample(frac=1)\n",
    "    train_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    test_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    label_prior_prob = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "\n",
    "    for k in range(kfold):\n",
    "        test_start = int(group_id_cnt*k/kfold)\n",
    "        test_end = int(group_id_cnt*(k+1)/kfold)\n",
    "        # Separate train and test\n",
    "        test_kth_fold = id_labels[test_start: test_end]\n",
    "        train_kth_fold = pd.concat([id_labels.iloc[0: test_start], id_labels.iloc[test_end:group_id_cnt]]) \n",
    "        total = len(train_kth_fold)\n",
    "        for l in range(labels): # For each fold, separate data with different labels\n",
    "            train_fold[k][l] = (train_kth_fold[train_kth_fold.label == l].group_id).tolist()\n",
    "            label_prior_prob[k][l] = len(train_fold[k][l])/total\n",
    "            test_fold[k][l] = (test_kth_fold[test_kth_fold.label == l].group_id).tolist()\n",
    "    return (label_prior_prob, train_fold, test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Build Naive Bayes classifier for each fold\n",
    "\n",
    " table_name: Name of the feature table\n",
    " \n",
    " ### Arguments\n",
    " * kfold: number of folds\n",
    " * labels: number of labels\n",
    " * train_fold: a k by l array. k fold of train set divided based on their labels\n",
    " \n",
    "### Returns\n",
    "params: a k by l by # of dist array. parameters of each distribution for each train set in each category of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildNaiveBayes(table_name, train_fold):\n",
    "    kfold = len(train_fold)\n",
    "    labels = len(train_fold[0])\n",
    "    params = [[{} for l in range(labels)] for k in range(kfold)]\n",
    "    cntr = 1\n",
    "    query_time = 0\n",
    "    fit_time = 0\n",
    "        \n",
    "    stime = time.time()\n",
    "    # Load list of distinct features\n",
    "    features = pd.read_sql('select feat, count(*) cnt from ' + table_name + ' group by feat', con=engine)\n",
    "    feat_cnt = len(features)\n",
    "    print(str(feat_cnt) + ' unique features' )\n",
    "    \n",
    "    # Load data, feature by feature, and set distribution parameters for each quadruple\n",
    "    # (fold, gender, feature, dist)\n",
    "    for index, eachfeat in features.iterrows():\n",
    "        feat = eachfeat.feat\n",
    "        qs = time.time()\n",
    "        feat = feat.replace(\"'\", \"''\").replace(\"%\", \"%%\").replace('\\\\', '\\\\\\\\')\n",
    "        fetch_data_query = \"select * from \" + table_name + \" where feat = '\" + feat + \"'\"\n",
    "        raw_df = pd.read_sql(fetch_data_query, con=engine)\n",
    "        qe = time.time()\n",
    "        \n",
    "        for k in range(kfold):\n",
    "            for l in range(labels):\n",
    "                params[k][l][feat] = {}\n",
    "                train = raw_df[raw_df.group_id.isin(train_fold[k][l])].group_norm.tolist()\n",
    "                train += [0] * (len(train_fold[k][l]) - len(train))\n",
    "                for dist in DISTRIBUTIONS:\n",
    "                    params[k][l][feat][dist] = mle(np.asarray(train), dist) # calc MLE\n",
    "                     \n",
    "        beste = time.time()\n",
    "        query_time += (qe-qs)\n",
    "        fit_time += (beste-qe)\n",
    "        print '\\r', str(cntr) + ' out of ' + str(feat_cnt) + ', ' + feat , \n",
    "        cntr += 1\n",
    "    etime = time.time()\n",
    "    print\n",
    "    print('overall time: ' + str(round(etime-stime)) + 's -> I/O time: ' + str(round(query_time)) + \\\n",
    "          's, run time: ' + str(round(fit_time)) + 's') \n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Naive Bayes for all Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_naiveBayes(table_name, test_fold, label_prior_prob, params):\n",
    "    kfold = len(test_fold)\n",
    "    labels = len(test_fold[0])\n",
    "    tp = {}\n",
    "    total = 0\n",
    "    label_tp = [0] * labels\n",
    "    label_total = [0] * labels\n",
    "    for l in range(labels):\n",
    "        label_tp[l] = {}\n",
    "        for dist in DISTRIBUTIONS:\n",
    "            tp[dist] = 0\n",
    "            label_tp[l][dist] = 0\n",
    "    group_id_cnt = 0\n",
    "    for k in range(kfold):\n",
    "        for l in range(labels):\n",
    "            group_id_cnt += len(test_fold[k][l])\n",
    "    print (\"Total number of test cases: \" + str(group_id_cnt))\n",
    "    cntr = 1\n",
    "    query_total_time = 0\n",
    "    run_time = 0\n",
    "    st = time.time()\n",
    "    for k in range(kfold):\n",
    "        for test_l in range(labels): \n",
    "            qs = time.time()\n",
    "            fetch_data_query = \"select * from \" + table_name + \\\n",
    "                \" where group_id in (\"+str(test_fold[k][test_l])[1:-1]+\")\"\n",
    "            test_df = pd.read_sql(fetch_data_query, con=engine)\n",
    "            qe = time.time()\n",
    "            query_total_time += (qe - qs)\n",
    "            for dist in DISTRIBUTIONS:\n",
    "                for id, grp in test_df.groupby(\"group_id\"):\n",
    "                    feats = grp.feat.replace(\"'\", \"''\").replace(\"%\", \"%%\").replace('\\\\', '\\\\\\\\')\n",
    "                    max_prob = float(\"-inf\")\n",
    "                    for l in range(labels):\n",
    "                        label_prob = np.log(label_prior_prob[k][l])\n",
    "                        for feat in feats:\n",
    "                            data = grp[grp.feat == feat].group_norm.tolist()\n",
    "                            label_prob += np.log(pdmf(np.asarray(data) , dist, params[k][l][feat][dist]))\n",
    "                        if label_prob > max_prob:\n",
    "                            best_label = l\n",
    "                            max_prob = label_prob\n",
    "                    # Track total number of test cases\n",
    "                    total += 1\n",
    "                    label_total[test_l] += 1\n",
    "                    # Track correct classifications as tp:True Positive\n",
    "                    if best_label == test_l:\n",
    "                        tp[dist] += 1\n",
    "                        label_tp[test_l][dist] += 1\n",
    "                    print '\\r' + str(cntr) + ' out of ' + str(group_id_cnt*len(tp)),\n",
    "                    cntr += 1\n",
    "            run_time += (time.time() - qe)\n",
    "    total /= len(DISTRIBUTIONS)\n",
    "    label_total = [lt/len(DISTRIBUTIONS) for lt in label_total]\n",
    "    et = time.time()\n",
    "    total_time = et-st\n",
    "    print \n",
    "    print (\"overall time: \" + str(round(total_time)) + \"s -> I/O time: \" + str(round(query_total_time)) + \\\n",
    "           \"s, run time: \" + str(round(run_time)) + \"s\")\n",
    "    return (total, label_total, tp, label_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Names\n",
    "\n",
    "It's important that table_name and label_table_name be synchronized together. \n",
    "That's why I put the definition of these two tables together in one chunck.\n",
    "\n",
    "Table_name is the name of the feature table we want to analyze which can be in each of the cnty, user, or message level. Depending on the level of feature table, label_table_name should be the name of the table containing list of group_ids and labels in the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_label_table_name = \"msgs_cntiesw10u10m_cnties_gender\"\n",
    "cliwc_table_name = \"feat$cat_LIWC2007$msgs_cntiesw10u10m$cnty$16to16\"\n",
    "ctopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_cntiesw10u10m$cnty$16to16\"\n",
    "c1gram_table_name = \"feat$1gram$msgs_cntiesw10u10m$cnty$16to16\"\n",
    "\n",
    "u_label_table_name = \"msgs_cntiesw10u10m_usrs_gender\"\n",
    "uliwc_table_name = \"feat$cat_LIWC2007$msgs_cntiesw10u10m$user_id$16to16\"\n",
    "utopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_cntiesw10u10m$user_id$16to16\"\n",
    "u1gram_table_name = \"feat$1gram$msgs_cntiesw10u10m$user_id$16to16\"\n",
    "\n",
    "m_label_table_name = \"msgs_w10u10m_mr20k_msgs_gender\"\n",
    "mliwc_table_name = \"feat$cat_LIWC2007$msgs_w10u10m_mr20k$message_id$16to16\"\n",
    "mtopic_table_name = \"feat$cat_met_a30_2000_cp_w$msgs_w10u10m_mr20k$message_id$16to16\"\n",
    "m1gram_table_name = \"feat$1gram$msgs_w10u10m_mr20k$message_id$16to16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all kfolds train and test in each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals: 872\n",
      "Total number of individuals: 9234\n",
      "Total number of individuals: 20000\n"
     ]
    }
   ],
   "source": [
    "c_label_prior_prob, c_train_fold, c_test_fold = generate_kfolds(c_label_table_name)\n",
    "\n",
    "u_label_prior_prob, u_train_fold, u_test_fold = generate_kfolds(u_label_table_name)\n",
    "\n",
    "m_label_prior_prob, m_train_fold, m_test_fold = generate_kfolds(m_label_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 2.0s -> I/O time: 1.0s, run time: 1.0s\n",
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 7.0s -> I/O time: 4.0s, run time: 3.0s\n",
      "64 unique features\n",
      "64 out of 64, YOU\n",
      "overall time: 7.0s -> I/O time: 2.0s, run time: 4.0s\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 60.0s -> I/O time: 28.0s, run time: 28.0s\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 432.0s -> I/O time: 263.0s, run time: 95.0s\n",
      "2000 unique features\n",
      "2000 out of 2000, 999\n",
      "overall time: 175.0s -> I/O time: 49.0s, run time: 118.0s\n",
      "1793072 unique features\n",
      "1 out of 1793072, !"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "min() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-4abdef285d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 1GRAMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mc1gram_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1gram_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mu1gram_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu1gram_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mm1gram_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1gram_table_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-e35868aedd8c>\u001b[0m in \u001b[0;36mbuildNaiveBayes\u001b[0;34m(table_name, train_fold)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mtrain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDISTRIBUTIONS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calc MLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbeste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-c453063e052f>\u001b[0m in \u001b[0;36mmle\u001b[0;34m(data, dist, zero)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# power law MLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: min() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# LIWC\n",
    "cliwc_params = buildNaiveBayes(cliwc_table_name, c_train_fold)\n",
    "uliwc_params = buildNaiveBayes(uliwc_table_name, u_train_fold)\n",
    "mliwc_params = buildNaiveBayes(mliwc_table_name, m_train_fold)\n",
    "\n",
    "# TOPICS\n",
    "ctopic_params = buildNaiveBayes(ctopic_table_name, c_train_fold)\n",
    "utopic_params = buildNaiveBayes(utopic_table_name, u_train_fold)\n",
    "mtopic_params = buildNaiveBayes(mtopic_table_name, m_train_fold)\n",
    "\n",
    "# 1GRAMS\n",
    "c1gram_params = buildNaiveBayes(c1gram_table_name, c_train_fold)\n",
    "u1gram_params = buildNaiveBayes(u1gram_table_name, u_train_fold)\n",
    "m1gram_params = buildNaiveBayes(m1gram_table_name, m_train_fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC , COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 872\n",
      "2616 out of 2616\n",
      "overall time: 237.0s -> I/O time: 0.0s, run time: 237.0s\n"
     ]
    }
   ],
   "source": [
    "cliwc_tot, cliwc_ltot, cliwc_tp, cliwc_ltp = \\\n",
    "test_naiveBayes(cliwc_table_name, c_test_fold, c_label_prior_prob, cliwc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 9234\n",
      "27699 out of 27702\n",
      "overall time: 2372.0s -> I/O time: 4.0s, run time: 2368.0s\n"
     ]
    }
   ],
   "source": [
    "uliwc_tot, uliwc_ltot, uliwc_tp, uliwc_ltp = \\\n",
    "test_naiveBayes(uliwc_table_name, u_test_fold, u_label_prior_prob, uliwc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total number of test cases: 20000\n",
      "57609 out of 60000\n",
      "overall time: 1359.0s -> I/O time: 3.0s, run time: 1356.0s\n"
     ]
    }
   ],
   "source": [
    "mliwc_tot, mliwc_ltot, mliwc_tp, mliwc_ltp = \\\n",
    "test_naiveBayes(mliwc_table_name, m_test_fold, m_label_prior_prob, mliwc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'zin_lognorm': 469, 'zin_norm': 458, 'zin_powerlaw': 406} out of 872.0\n",
      "{'zin_lognorm': 5081, 'zin_norm': 5645, 'zin_powerlaw': 4290} 9233.0\n",
      "{'zin_lognorm': 10220, 'zin_norm': 10105, 'zin_powerlaw': 10162} 19203.0\n",
      "\n",
      "\n",
      "\n",
      "[{'zin_lognorm': 325, 'zin_norm': 301, 'zin_powerlaw': 78}, {'zin_lognorm': 144, 'zin_norm': 157, 'zin_powerlaw': 328}] [436.0, 436.0]\n",
      "[{'zin_lognorm': 1860, 'zin_norm': 2887, 'zin_powerlaw': 8}, {'zin_lognorm': 3221, 'zin_norm': 2758, 'zin_powerlaw': 4282}] [4943.0, 4290.0]\n",
      "[{'zin_lognorm': 5962, 'zin_norm': 5996, 'zin_powerlaw': 8198}, {'zin_lognorm': 4258, 'zin_norm': 4109, 'zin_powerlaw': 1964}] [10589.0, 8614.0]\n"
     ]
    }
   ],
   "source": [
    "print cliwc_tp, \"out of\", cliwc_tot\n",
    "print uliwc_tp, uliwc_tot\n",
    "print mliwc_tp, mliwc_tot\n",
    "print '\\n\\n'\n",
    "print cliwc_ltp, cliwc_ltot\n",
    "print uliwc_ltp, uliwc_ltot\n",
    "print mliwc_ltp, mliwc_ltot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 872\n",
      "1165 out of 2616 "
     ]
    }
   ],
   "source": [
    "ctopic_tp, ctopic_ltp = test_naiveBayes(ctopic_table_name, c_test_fold, c_label_prior_prob, ctopic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utopic_tp, utopic_ltp = test_naiveBayes(utopic_table_name, u_test_fold, u_label_prior_prob, utopic_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utopic_tp, utopic_ltp = test_naiveBayes(mtopic_table_name, m_test_fold, m_label_prior_prob, mtopic_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
