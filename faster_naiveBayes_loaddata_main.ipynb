{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "execute_notebook : A method to load and execute another notebook in this notebook's namespace\n",
    "\n",
    "cite: http://nbviewer.jupyter.org/gist/minrk/5491090/analysis.ipynb\n",
    "\n",
    "Call it for your notebook that want to import here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "def execute_notebook(nbfile):\n",
    "    \n",
    "    with io.open(nbfile) as f:\n",
    "        nb = current.read(f, 'json')\n",
    "    \n",
    "    ip = get_ipython()\n",
    "    \n",
    "    for cell in nb.worksheets[0].cells:\n",
    "        if cell.cell_type != 'code':\n",
    "            continue\n",
    "        ip.run_cell(cell.input)\n",
    "execute_notebook(\"distributions_fit_and_likelihood.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary packages and libraries to connect to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "twitter_db = 'twitterGender'\n",
    "import MySQLdb\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "connection = MySQLdb.connect (db = twitter_db, read_default_file=\"/home/fatal/.my.cnf\")\n",
    "cursor = connection.cursor ()\n",
    "small_val = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DISTRIBUTIONS = [\n",
    "    'norm', 'lognorm', 'powerlaw', 'zin_norm', 'zin_lognorm', 'zin_powerlaw', 'bernoulli'\n",
    "]\n",
    "kfold = 10\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate k random folds of train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_kfolds(label_table_name):\n",
    "    # Load DATA from DB\n",
    "    cursor.execute ('select group_id, label from ' + label_table_name)\n",
    "    id_labels = list(cursor.fetchall())\n",
    "\n",
    "    group_id_cnt = len(id_labels)\n",
    "    print (\"Total number of individuals: \" + str(group_id_cnt))\n",
    "    # generating k-folds of ids\n",
    "    #random.shuffle() works for lists\n",
    "    np.random.shuffle(id_labels)\n",
    "    #id_labels = id_labels.sample(frac=1)\n",
    "\n",
    "    train_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    test_fold = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "    label_prior_prob = [[0 for x in range(labels)] for y in range(kfold)]\n",
    "\n",
    "    for k in range(kfold):\n",
    "        test_start = int(group_id_cnt*k/kfold)\n",
    "        test_end = int(group_id_cnt*(k+1)/kfold)\n",
    "        # Separate train and test\n",
    "        test_kth_fold = id_labels[test_start: test_end]\n",
    "        train_kth_fold = id_labels[0: test_start] + id_labels[test_end:group_id_cnt] \n",
    "        total = len(train_kth_fold)\n",
    "        for l in range(labels): # For each fold, separate data with different labels\n",
    "            train_fold[k][l] = [int(t[0]) for t in train_kth_fold if t[1] == l]\n",
    "            label_prior_prob[k][l] = len(train_fold[k][l])/total\n",
    "            test_fold[k][l] = [int(t[0]) for t in test_kth_fold if t[1] == l]\n",
    "    return (label_prior_prob, train_fold, test_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Build Naive Bayes classifier for each fold\n",
    "\n",
    " table_name: Name of the feature table\n",
    " \n",
    " ### Arguments\n",
    " * kfold: number of folds\n",
    " * labels: number of labels\n",
    " * train_fold: a k by l array. k fold of train set divided based on their labels\n",
    " \n",
    "### Returns\n",
    "params: a k by l by # of dist array. parameters of each distribution for each train set in each category of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def buildNaiveBayes(table_name, train_fold):\n",
    "    kfold = len(train_fold)\n",
    "    labels = len(train_fold[0])\n",
    "    params = [[{} for l in range(labels)] for k in range(kfold)]\n",
    "    defaults = [[init_default() for l in range(labels)] for k in range(kfold)]\n",
    "    cntr = 1\n",
    "    query_time = 0\n",
    "    fit_time = 0\n",
    "        \n",
    "    stime = time.time()\n",
    "    # Load list of distinct features\n",
    "    cursor.execute('select feat, count(*) cnt from ' + table_name + ' group by feat')\n",
    "    features = list(cursor.fetchall())\n",
    "    feat_cnt = len(features)\n",
    "    print(str(feat_cnt) + ' unique features' )\n",
    "    \n",
    "    # Load data, feature by feature, and set distribution parameters for each quadruple\n",
    "    # (fold, gender, feature, dist)\n",
    "    problematic = {}\n",
    "    for eachfeat in features:\n",
    "        feat = eachfeat[0]\n",
    "        qs = time.time()\n",
    "        feat2search = feat.replace(\"'\", \"''\").replace(\"%\", \"%%\").replace(\"\\\\\", \"\\\\\\\\\")\n",
    "        GROUP_ID = 0; FEAT = 1; VALUE=2; GROUP_NORM = 3\n",
    "        fetch_data_query = \"select group_id, feat, value, group_norm from \" + \\\n",
    "        table_name + \" where feat = '\" + feat2search + \"'\"\n",
    "        cursor.execute(fetch_data_query)\n",
    "        raw_df = list(cursor.fetchall())\n",
    "        qe = time.time()\n",
    "        \n",
    "        train = {}        \n",
    "        for row in raw_df:\n",
    "            train[int(row[GROUP_ID])] = [row[VALUE], row[GROUP_NORM]]\n",
    "\n",
    "        for k in range(kfold):\n",
    "            for l in range(labels):\n",
    "                params[k][l][feat] = {}\n",
    "                # select group_norm and value of those group_ids in train_fold[k][l]\n",
    "                aa = time.time()\n",
    "                train_count, train_grpnrm, train_count_zero, train_grpnrm_zero = [], [], [], []\n",
    "                for t in train_fold[k][l]:\n",
    "                    if t in train:\n",
    "                        train_count += [train[t][0]] # value\n",
    "                        train_grpnrm += [train[t][1]] # group_norm\n",
    "                    else:\n",
    "                        train_grpnrm_zero += [0]\n",
    "                        train_count_zero += [0]\n",
    "                train_grpnrm_zero += train_grpnrm \n",
    "                train_count_zero += train_count \n",
    "                if len(train_count) <= 1:\n",
    "                    problematic[feat] = True\n",
    "                defaults[k][l] = update_default(train_grpnrm_zero, defaults[k][l]) # calc default\n",
    "                for dist in DISTRIBUTIONS:\n",
    "                    if dist == 'binomial' or dist == 'bernoulli':\n",
    "                        params[k][l][feat][dist] = mle(train_count_zero, dist) # calc MLE                        \n",
    "                    elif 'zin' in dist:\n",
    "                        params[k][l][feat][dist] = mle(train_grpnrm_zero, dist) # calc MLE\n",
    "                    else:\n",
    "                        params[k][l][feat][dist] = mle(train_grpnrm, dist) # calc MLE\n",
    "                    \n",
    "                    #if dist == 'zin_norm' and random.randint(0, 10) == 0:\n",
    "                    #    plt.hist(train_grpnrm_zero, bins=200)\n",
    "        beste = time.time()\n",
    "        query_time += (qe-qs)\n",
    "        fit_time += (beste-qe)\n",
    "        print '\\r', str(cntr) + ' out of ' + str(feat_cnt) + ', ' + feat + ', ' + str(round(beste-qe, 2)),\n",
    "        cntr += 1\n",
    "    etime = time.time()\n",
    "    print\n",
    "    print('overall time: ' + str(round(etime-stime)) + 's -> I/O time: ' + str(round(query_time)) + \\\n",
    "          's, run time: ' + str(round(fit_time)) + 's') \n",
    "    print (\"problematic length:{}\".format(len(problematic.keys())))\n",
    "    print problematic.keys()\n",
    "    return params, defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Naive Bayes for all Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "def test_naiveBayes(table_name, test_fold, label_prior_prob, params, defaults):\n",
    "    kfold = len(test_fold)\n",
    "    labels = len(test_fold[0])\n",
    "    tp = {}\n",
    "    total = 0\n",
    "    label_tp = [0] * labels\n",
    "    label_total = [0] * labels\n",
    "    # as we should have a distribution for all features in all kfolds and labels, it doesn't matter which k or l\n",
    "    # we choose to get list of all features from \n",
    "    all_feats = set(params[0][0].keys())\n",
    "    for l in range(labels):\n",
    "        label_tp[l] = {}\n",
    "        for dist in DISTRIBUTIONS:\n",
    "            tp[dist] = 0\n",
    "            label_tp[l][dist] = 0\n",
    "    group_id_cnt = 0\n",
    "    for k in range(kfold):\n",
    "        for l in range(labels):\n",
    "            group_id_cnt += len(test_fold[k][l])\n",
    "    print (\"Total number of test cases: \" + str(group_id_cnt))\n",
    "    cntr = 1\n",
    "    query_total_time = 0\n",
    "    run_time = 0\n",
    "    st = time.time()\n",
    "    for k in range(kfold):\n",
    "        for test_l in range(labels): \n",
    "            qs = time.time()\n",
    "            GROUP_ID = 0; FEAT = 1; VALUE=2; GROUP_NORM = 3\n",
    "            fetch_data_query = \"select group_id, feat, value, group_norm from \" + table_name + \\\n",
    "                \" where group_id in (\"+str(test_fold[k][test_l])[1:-1]+\")\"\n",
    "            cursor.execute(fetch_data_query)\n",
    "            test_df = cursor.fetchall()\n",
    "            qe = time.time()\n",
    "            query_total_time += (qe - qs)\n",
    "            # separate results into groups of all features for each group_id\n",
    "            grps = {}\n",
    "            for t in test_df:\n",
    "                key = int(t[GROUP_ID])\n",
    "                # I'll add all four just to keep indexing for static values GROUP_ID, FEAT, VALUE, & GROUP_NORM\n",
    "                if key in grps:\n",
    "                    grps[key] += [[key, t[FEAT], t[VALUE], t[GROUP_NORM]]] \n",
    "                else:\n",
    "                    grps[key] = [[key, t[FEAT], t[VALUE], t[GROUP_NORM]]]\n",
    "            for key in grps:\n",
    "                s1 = time.time()\n",
    "                # select features that have'nt been used by this id\n",
    "                zero_feats = all_feats - set([g[2] for g in grps[key]]) \n",
    "                t3 = time.time()\n",
    "                for dist in DISTRIBUTIONS:\n",
    "                    max_prob = float(\"-inf\")\n",
    "                    best_label = -1\n",
    "                    for l in range(labels): # go through all classes to find best class as the match label\n",
    "                        label_prob = np.log(label_prior_prob[k][l])     \n",
    "                        ll = label_prob\n",
    "                        t4 = time.time()\n",
    "                        for row in grps[key]: # go over all available features of an individual\n",
    "                            if params[k][l][row[FEAT]][dist]['cnt'] > 1:\n",
    "                                if dist == 'binomial' or dist == 'bernoulli':\n",
    "                                    data = row[VALUE]\n",
    "                                else:\n",
    "                                    data = row[GROUP_NORM]\n",
    "                                label_prob += np.log(singleval_pdmf(data , dist, \\\n",
    "                                                                params[k][l][row[FEAT]][dist], defaults[k][l]))\n",
    "                            #if dist == 'zin_norm' and math.isnan(label_prob):\n",
    "                            #    pdb.set_trace()\n",
    "                            #    print(\"something\")\n",
    "                        t5 = time.time()\n",
    "                        if dist == 'binomial':\n",
    "                            for feat in zero_feats: # go over all non-available features of an individual\n",
    "                                label_prob += params[k][l][feat][dist]['cnt']*params[k][l][feat][dist]['logp0']\n",
    "                            \n",
    "                        if 'zin' in dist or dist == 'bernoulli':\n",
    "                            for feat in zero_feats: # go over all non-available features of an individual\n",
    "                                label_prob += params[k][l][feat][dist]['logp0']\n",
    "                        t6 = time.time()\n",
    "                        #if test_l == 1 and dist == 'zin_norm':\n",
    "                        #    print (\"{}, {}, {}\".format(l, label_prob, ll))\n",
    "                        if label_prob > max_prob: # choose best label with maximum probability\n",
    "                            best_label = l\n",
    "                            max_prob = label_prob\n",
    "                    # Track correct classifications as tp:True Positive\n",
    "                    if best_label == test_l:\n",
    "                        tp[dist] += 1\n",
    "                        label_tp[test_l][dist] += 1\n",
    "                e1 = time.time()\n",
    "                print '\\r' + str(cntr) + ' out of ' + str(group_id_cnt), str(round(e1-s1, 2)), \n",
    "                cntr += 1\n",
    "                # Track total number of test cases\n",
    "                total += 1\n",
    "                label_total[test_l] += 1\n",
    "            run_time += (time.time() - qe)\n",
    "    et = time.time()\n",
    "    total_time = et-st\n",
    "    print \n",
    "    print (\"overall time: \" + str(round(total_time)) + \"s -> I/O time: \" + str(round(query_total_time)) + \\\n",
    "           \"s, run time: \" + str(round(run_time)) + \"s\")\n",
    "    return (total, label_total, tp, label_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Names\n",
    "\n",
    "It's important that table_name and label_table_name be synchronized together. \n",
    "That's why I put the definition of these two tables together in one chunck.\n",
    "\n",
    "Table_name is the name of the feature table we want to analyze which can be in each of the cnty, user, or message level. Depending on the level of feature table, label_table_name should be the name of the table containing list of group_ids and labels in the same level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_label_table_name = \"cntygndr_uwt1k_upc30_ctw5k\"\n",
    "cliwc_table_name = \"feat$cat_LIWC2007$cntymsg_u1kupc30c5k$cnty$16to16\"\n",
    "ctopic_table_name = \"feat_topic_cnty_freqfeat_u1kupc30c5k\"\n",
    "c1gram_table_name = \"feat_1gram_cnty_freqfeat_u1kupc30c5k\"\n",
    "\n",
    "u_label_table_name = \"usrgndr_uwt1k_upc30_ctw5k\"\n",
    "uliwc_table_name = \"feat$cat_LIWC2007$usrmsg_u1kupc30c5k$user_id$16to16\"\n",
    "utopic_table_name = \"feat_topic_usr_freqfeat_u1kupc30c5k\"\n",
    "u1gram_table_name = \"feat_1gram_usr_freqfeat_u1kupc30c5k\"\n",
    "\n",
    "m_label_table_name = \"msggndr_uwt1k_upc30_ctw5k\"\n",
    "mliwc_table_name = \"feat$cat_LIWC2007$msg_u1kupc30c5k$message_id$16to16\"\n",
    "mtopic_table_name = \"feat_topic_msg_freqfeat_u1kupc30c5k\"\n",
    "m1gram_table_name = \"feat_1gram_msg_freqfeat_u1kupc30c5k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define all kfolds train and test in each level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals: 280\n",
      "Total number of individuals: 5044\n",
      "Total number of individuals: 5044\n"
     ]
    }
   ],
   "source": [
    "c_label_prior_prob, c_train_fold, c_test_fold = generate_kfolds(c_label_table_name)\n",
    "\n",
    "u_label_prior_prob, u_train_fold, u_test_fold = generate_kfolds(u_label_table_name)\n",
    "\n",
    "m_label_prior_prob, m_train_fold, m_test_fold = generate_kfolds(m_label_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOPICS, COUNTY\n",
      "200 unique features\n",
      "200 out of 200, 997, 0.15\n",
      "overall time: 73.0s -> I/O time: 0.0s, run time: 73.0s\n",
      "problematic length:0\n",
      "[]\n",
      "\n",
      "TOPICS, USER\n",
      "742 unique features\n",
      "742 out of 742, 997, 0.35\n",
      "overall time: 368.0s -> I/O time: 33.0s, run time: 334.0s\n",
      "problematic length:0\n",
      "[]\n",
      "\n",
      "TOPICS, MESSAGE\n",
      "742 unique features\n",
      "742 out of 742, 997, 0.18\n",
      "overall time: 258.0s -> I/O time: 3.0s, run time: 254.0s\n",
      "problematic length:0\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\necZXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14c0175d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LIWC\n",
    "print '\\nLIWC, COUNTY'; cliwc_params, cliwc_defaults = buildNaiveBayes(cliwc_table_name, c_train_fold)\n",
    "print '\\nLIWC, USER'; uliwc_params, uliwc_defaults = buildNaiveBayes(uliwc_table_name, u_train_fold)\n",
    "print '\\nLIWC, MESSAGE'; mliwc_params, mliwc_defaults = buildNaiveBayes(mliwc_table_name, m_train_fold)\n",
    "\n",
    "# TOPICS\n",
    "print '\\nTOPICS, COUNTY'; ctopic_params, ctopic_defaults = buildNaiveBayes(ctopic_table_name, c_train_fold)\n",
    "print '\\nTOPICS, USER'; utopic_params, utopic_defaults = buildNaiveBayes(utopic_table_name, u_train_fold)\n",
    "print '\\nTOPICS, MESSAGE'; mtopic_params, mtopic_defaults = buildNaiveBayes(mtopic_table_name, m_train_fold)\n",
    "\n",
    "# 1GRAMS\n",
    "print '\\n1GRAM, COUNTY'; c1gram_params, c1gram_defaults = buildNaiveBayes(c1gram_table_name, c_train_fold)\n",
    "print '\\n1GRAM, USER'; u1gram_params, u1gram_defaults = buildNaiveBayes(u1gram_table_name, u_train_fold)\n",
    "print '\\n1GRAM, MESSAGE'; m1gram_params, m1gram_defaults = buildNaiveBayes(m1gram_table_name, m_train_fold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC , COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 280\n",
      "\n",
      "overall time: 2.0s -> I/O time: 0.0s, run time: 2.0s\n"
     ]
    }
   ],
   "source": [
    "cliwc_tot, cliwc_ltot, cliwc_tp, cliwc_ltp = \\\n",
    "test_naiveBayes(cliwc_table_name, c_test_fold, c_label_prior_prob, cliwc_params, cliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "\n",
      "overall time: 39.0s -> I/O time: 2.0s, run time: 37.0s\n"
     ]
    }
   ],
   "source": [
    "uliwc_tot, uliwc_ltot, uliwc_tp, uliwc_ltp = \\\n",
    "test_naiveBayes(uliwc_table_name, u_test_fold, u_label_prior_prob, uliwc_params, uliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "\n",
      "overall time: 9.0s -> I/O time: 1.0s, run time: 9.0s\n"
     ]
    }
   ],
   "source": [
    "mliwc_tot, mliwc_ltot, mliwc_tp, mliwc_ltp = \\\n",
    "test_naiveBayes(mliwc_table_name, m_test_fold, m_label_prior_prob, mliwc_params, mliwc_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      norm      lognorm     powerlaw     zin_norm  zin_lognorm zin_powerlaw    bernoulli\n",
      "       county         0.57         0.57         0.51         0.56         0.56         0.51         0.56\n",
      "         user         0.54         0.55         0.54         0.54         0.54         0.46         0.65\n",
      "      message         0.48         0.55         0.46         0.48         0.51          0.5         0.53\n",
      "\n",
      "\t\t\t######### gender = 0 #########\n",
      "       county         0.52         0.57         0.05         0.36         0.51         0.06         0.56\n",
      "         user          1.0         0.36          1.0          1.0          1.0          0.0         0.61\n",
      "      message         0.19         0.79         0.04         0.15         0.45         0.36         0.76\n",
      "\n",
      "\t\t\t######### gender = 1 #########\n",
      "       county         0.63         0.57         0.97         0.76         0.61         0.96         0.57\n",
      "         user          0.0         0.77          0.0          0.0          0.0          1.0          0.7\n",
      "      message         0.82         0.26         0.96         0.87         0.58         0.67         0.25\n"
     ]
    }
   ],
   "source": [
    "row_format =\"{:>13}\" * (len(DISTRIBUTIONS) + 1)\n",
    "print row_format.format(\"\", *DISTRIBUTIONS)\n",
    "\n",
    "#for team, row in zip(teams_list, data):\n",
    "#    print row_format.format(team, *row)\n",
    "row = ['county']\n",
    "for k, v in cliwc_tp.iteritems():\n",
    "    row += [round(v/cliwc_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['user']\n",
    "for k, v in uliwc_tp.iteritems():\n",
    "    row += [round(v/uliwc_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['message']\n",
    "for k, v in mliwc_tp.iteritems():\n",
    "    row += [round(v/mliwc_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "for l in range(labels):\n",
    "    print \"\\n\" + \"\\t\"*3 +\"######### gender = {} #########\".format(l)\n",
    "    row = ['county']\n",
    "    for k, v in cliwc_ltp[l].iteritems():\n",
    "        row += [round(v/cliwc_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['user']\n",
    "    for k, v in uliwc_ltp[l].iteritems():\n",
    "        row += [round(v/uliwc_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['message']\n",
    "    for k, v in mliwc_ltp[l].iteritems():\n",
    "        row += [round(v/mliwc_ltot[l], 2)]\n",
    "    print row_format.format(*row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 280\n",
      "280 out of 280 0.03\n",
      "overall time: 7.0s -> I/O time: 0.0s, run time: 7.0s\n"
     ]
    }
   ],
   "source": [
    "ctopic_tot, ctopic_ltot, ctopic_tp, ctopic_ltp = \\\n",
    "test_naiveBayes(ctopic_table_name, c_test_fold, c_label_prior_prob, ctopic_params, ctopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "5044 out of 5044 0.1\n",
      "overall time: 514.0s -> I/O time: 19.0s, run time: 495.0s\n"
     ]
    }
   ],
   "source": [
    "utopic_tot, utopic_ltot, utopic_tp, utopic_ltp = \\\n",
    "test_naiveBayes(utopic_table_name, u_test_fold, u_label_prior_prob, utopic_params, utopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "4817 out of 5044 0.03\n",
      "overall time: 92.0s -> I/O time: 3.0s, run time: 89.0s\n"
     ]
    }
   ],
   "source": [
    "mtopic_tot, mtopic_ltot, mtopic_tp, mtopic_ltp = \\\n",
    "test_naiveBayes(mtopic_table_name, m_test_fold, m_label_prior_prob, mtopic_params, mtopic_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      norm      lognorm     powerlaw     zin_norm  zin_lognorm zin_powerlaw    bernoulli\n",
      "       county          0.6          0.6          0.5         0.56         0.53          0.5         0.51\n",
      "         user         0.54         0.55         0.54         0.54         0.53         0.46         0.58\n",
      "      message         0.52         0.54         0.51          0.5         0.51         0.54         0.51\n",
      "\n",
      "\t\t\t######### gender = 0 #########\n",
      "       county         0.67         0.71         0.11         0.66         0.58          0.1         0.57\n",
      "         user          1.0         0.35          1.0          1.0         0.98          0.0         0.42\n",
      "      message         0.45         0.58         0.47         0.35         0.55          0.8         0.57\n",
      "\n",
      "\t\t\t######### gender = 1 #########\n",
      "       county         0.54         0.49         0.89         0.46         0.48         0.91         0.46\n",
      "         user          0.0          0.8          0.0          0.0          0.0          1.0         0.78\n",
      "      message          0.6         0.48         0.56         0.68         0.47         0.24         0.44\n"
     ]
    }
   ],
   "source": [
    "row_format =\"{:>13}\" * (len(DISTRIBUTIONS) + 1)\n",
    "print row_format.format(\"\", *DISTRIBUTIONS)\n",
    "\n",
    "#for team, row in zip(teams_list, data):\n",
    "#    print row_format.format(team, *row)\n",
    "row = ['county']\n",
    "for k, v in ctopic_tp.iteritems():\n",
    "    row += [round(v/ctopic_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['user']\n",
    "for k, v in utopic_tp.iteritems():\n",
    "    row += [round(v/utopic_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['message']\n",
    "for k, v in mtopic_tp.iteritems():\n",
    "    row += [round(v/mtopic_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "for l in range(labels):\n",
    "    print \"\\n\" + \"\\t\"*3 +\"######### gender = {} #########\".format(l)\n",
    "    row = ['county']\n",
    "    for k, v in ctopic_ltp[l].iteritems():\n",
    "        row += [round(v/ctopic_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['user']\n",
    "    for k, v in utopic_ltp[l].iteritems():\n",
    "        row += [round(v/utopic_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['message']\n",
    "    for k, v in mtopic_ltp[l].iteritems():\n",
    "        row += [round(v/mtopic_ltot[l], 2)]\n",
    "    print row_format.format(*row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 280\n",
      "280 out of 280 0.02\n",
      "overall time: 7.0s -> I/O time: 0.0s, run time: 7.0s\n"
     ]
    }
   ],
   "source": [
    "c1gram_tot, c1gram_ltot, c1gram_tp, c1gram_ltp = \\\n",
    "test_naiveBayes(c1gram_table_name, c_test_fold, c_label_prior_prob, c1gram_params, c1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "5044 out of 5044 0.05\n",
      "overall time: 256.0s -> I/O time: 9.0s, run time: 247.0s\n"
     ]
    }
   ],
   "source": [
    "u1gram_tot, u1gram_ltot, u1gram_tp, u1gram_ltp = \\\n",
    "test_naiveBayes(u1gram_table_name, u_test_fold, u_label_prior_prob, u1gram_params, u1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, MESSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases: 5044\n",
      "4983 out of 5044 0.0\n",
      "overall time: 19.0s -> I/O time: 0.0s, run time: 19.0s\n"
     ]
    }
   ],
   "source": [
    "m1gram_tot, m1gram_ltot, m1gram_tp, m1gram_ltp = \\\n",
    "test_naiveBayes(m1gram_table_name, m_test_fold, m_label_prior_prob, m1gram_params, m1gram_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1GRAM, Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      norm      lognorm     powerlaw     zin_norm  zin_lognorm zin_powerlaw    bernoulli\n",
      "       county         0.55         0.58         0.51         0.51         0.57          0.5         0.59\n",
      "         user         0.55         0.62         0.54         0.54         0.62         0.46         0.58\n",
      "      message          0.5          0.5          0.5         0.57          0.5          0.5          0.5\n",
      "\n",
      "\t\t\t######### gender = 0 #########\n",
      "       county         0.59         0.64         0.01         0.51         0.63         0.07         0.63\n",
      "         user          1.0          0.5         0.95          1.0         0.84         0.01         0.42\n",
      "      message          0.6          0.6         0.38         0.65         0.58         0.38         0.58\n",
      "\n",
      "\t\t\t######### gender = 1 #########\n",
      "       county         0.51         0.53          1.0         0.51         0.51         0.93         0.54\n",
      "         user         0.01         0.76         0.06          0.0         0.36         0.99         0.77\n",
      "      message         0.37         0.38         0.64         0.46         0.39         0.64          0.4\n"
     ]
    }
   ],
   "source": [
    "row_format =\"{:>13}\" * (len(DISTRIBUTIONS) + 1)\n",
    "print row_format.format(\"\", *DISTRIBUTIONS)\n",
    "\n",
    "#for team, row in zip(teams_list, data):\n",
    "#    print row_format.format(team, *row)\n",
    "row = ['county']\n",
    "for k, v in c1gram_tp.iteritems():\n",
    "    row += [round(v/c1gram_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['user']\n",
    "for k, v in u1gram_tp.iteritems():\n",
    "    row += [round(v/u1gram_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "row = ['message']\n",
    "for k, v in m1gram_tp.iteritems():\n",
    "    row += [round(v/m1gram_tot, 2)]\n",
    "print row_format.format(*row)\n",
    "\n",
    "for l in range(labels):\n",
    "    print \"\\n\" + \"\\t\"*3 +\"######### gender = {} #########\".format(l)\n",
    "    row = ['county']\n",
    "    for k, v in c1gram_ltp[l].iteritems():\n",
    "        row += [round(v/c1gram_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['user']\n",
    "    for k, v in u1gram_ltp[l].iteritems():\n",
    "        row += [round(v/u1gram_ltot[l], 2)]\n",
    "    print row_format.format(*row)\n",
    "\n",
    "    row = ['message']\n",
    "    for k, v in m1gram_ltp[l].iteritems():\n",
    "        row += [round(v/m1gram_ltot[l], 2)]\n",
    "    print row_format.format(*row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
