{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Libraries & Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import logging\n",
    "\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "Zero = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables\n",
    "* cnt = 0 # count of all non-zero data points\n",
    "* dsum = 0 # sum of all non-zero data point values for all features\n",
    "* d2sum = 0 # sum of all non-zero data point values squared for all features\n",
    "\n",
    "\n",
    "* cnt0 = 0 # count of all data points\n",
    "* dsum0 = 0 # sum of all data point values for all features\n",
    "* d2sum0 = 0 # sum of all data point values squared for all features\n",
    "\n",
    "\n",
    "* lndsum = 0 # sum of log of all non-zero data point values for all features\n",
    "* lnd2sum = 0 # sum of log of all non-zero data point values squared for all features\n",
    "* xmin = -1 # minimum among all of non-zero data point values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_default():\n",
    "    return {'cnt':0, 'dsum':0, 'd2sum':0, 'lndsum':0, 'lnd2sum':0, 'xmin':float(\"inf\"), \\\n",
    "            'cnt0':0, 'dsum0':0, 'd2sum0':0}\n",
    "\n",
    "def update_default(data, default):\n",
    "    data = np.asarray(data)\n",
    "    default['cnt0'] += len(data)\n",
    "    default['dsum0'] += np.sum(data)\n",
    "    default['d2sum0'] += np.sum(data**2)\n",
    "    data = data[data > 0]\n",
    "    default['cnt'] += len(data)\n",
    "    default['dsum'] += np.sum(data)\n",
    "    default['d2sum'] += np.sum(data**2)\n",
    "    if len(data) > 0:\n",
    "        default['xmin'] = min(min(data), default['xmin'])\n",
    "    lndata = np.log(data)\n",
    "    default['lndsum'] += np.sum(lndata)\n",
    "    default['lnd2sum'] += np.sum(lndata**2)\n",
    "    return default\n",
    "    \n",
    "def use_default(dist, default):\n",
    "    loc = -1\n",
    "    scale = -1\n",
    "    shape = -1\n",
    "    if dist == 'norm':\n",
    "        loc = default['dsum0']/default['cnt0']\n",
    "        scale = np.sqrt(default['d2sum0']/default['cnt0']-loc**2)        \n",
    "    elif dist == \"lognorm\":\n",
    "        loc = default['lndsum']/default['cnt']\n",
    "        scale = np.sqrt(default['lnd2sum']/default['cnt']-loc**2)\n",
    "    elif dist == \"powerlaw\":\n",
    "        shape = 1 + default['cnt']/(default['lndsum'] - default['cnt']*np.log(default['xmin']))\n",
    "    elif dist == \"zin_norm\":\n",
    "        loc = default['dsum']/default['cnt']\n",
    "        scale = np.sqrt(default['d2sum']/default['cnt']-loc**2)\n",
    "    elif dist == \"zin_lognorm\":\n",
    "        loc = default['lndsum']/default['cnt']\n",
    "        scale = np.sqrt(default['lnd2sum']/default['cnt']-loc**2)\n",
    "    elif dist == \"zin_powerlaw\":\n",
    "        shape = 1 + default['cnt']/(default['lndsum'] - default['cnt']*np.log(default['xmin']))\n",
    "    return (loc, scale, shape, default['xmin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation\n",
    "The following methods calculate MLE of different distributions based on the input empirical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE calculator returns at most 4 parameters for the distributions \"normal\", \"log-normal\", \"power law\", \"fisk\", \"binomial\", \"zero-inflated log-normal\", and \"zero-inflated power law\".\n",
    "1. locale -> key: loc\n",
    "2. scale -> key: scale\n",
    "3. shape -> key: shape\n",
    "\n",
    "input zero shows the real number that should be considered as zero if the data is normalized into 0.005 to 1 of range of x.\n",
    "\n",
    "NOTE: WHEN N, COUNT OF DATA TO CALCULATE MLE, AND N', COUNT OF OUT-OF-SAMPLE DATA TO CALCULATE LIKELIHOOD ON ARE NOT EQUAL, VALUE OF ZERO IS NOT THE SAME. DON'T KNOW WHAT WE SHOULD DO IN THIS CASE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mle(data, dist, zero = 0): \n",
    "    data = np.asarray(data) # data is of type np.array\n",
    "    loc = -1\n",
    "    scale = -1\n",
    "    shape = -1\n",
    "    p0 = -1 # Probability of being zero in zero-inflated distributions\n",
    "    x_min = -1\n",
    "    cnt = len(data)\n",
    "    warningMsg = \"Data out of range for \" + dist + \". Will remove \"\n",
    "    #logging.warn(warningMsg.format(\"x<=0\"))\n",
    "    if dist == 'norm': # MLE for Normal\n",
    "        if len(data) > 1:\n",
    "            loc = np.mean(data)\n",
    "            scale = np.std(data)\n",
    "    \n",
    "    elif dist == 'lognorm': # MLE for Log-normal\n",
    "        if len(data) > 1:\n",
    "            if min(data) <= 0:\n",
    "                logging.warn(warningMsg+\"x <= 0\")\n",
    "                data = data[data > 0]\n",
    "            if len(data) > 1: # O.W. we will use default in pdmf\n",
    "                lndata = np.log(data)\n",
    "                loc = np.mean(lndata)\n",
    "                scale = np.std(lndata)\n",
    "            \n",
    "    \n",
    "    elif dist == 'powerlaw': # MLE for Power Law\n",
    "        if len(data) != 0:\n",
    "            if min(data) <= 0:\n",
    "                logging.warn(warningMsg+\"x <= 0\")\n",
    "                data = data[data > 0]\n",
    "            # x_min is just set to the smallest non-zero x\n",
    "            if len(data) != 0: # O.W. we will use default in pdmf\n",
    "                x_min = min(data)\n",
    "                shape = 1 + len(data)/(np.sum(np.log(data/x_min)))\n",
    "    \n",
    "    elif dist == 'zin_norm': # MLE for Zero-Inflated Normal\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        data = data[data >= zero]\n",
    "        p0 = (len(data[data == zero])+1)/(len(data)+2) # laplace smoothing to scape zeros\n",
    "        data = data[data > zero]\n",
    "        if len(data) != 0: # O.W. we will use default in pdmf\n",
    "            # normal MLE\n",
    "            loc = np.mean(data)\n",
    "            scale = np.std(data)     \n",
    "        \n",
    "    elif dist == 'zin_lognorm': # MLE for Zero-Inflated Log-normal\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        data = data[data >= zero]\n",
    "        p0 = (len(data[data == zero])+1)/(len(data)+2)\n",
    "        data = data[data > zero]\n",
    "        if len(data) != 0: # O.W. we will use default in pdmf\n",
    "            # log-normal MLE\n",
    "            lndata = np.log(data)\n",
    "            loc = np.mean(lndata)\n",
    "            scale = np.std(lndata)\n",
    "        \n",
    "    elif dist == 'zin_powerlaw': # MLE for Zero-Inflated Power Law\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        data = data[data >= zero]\n",
    "        p0 = (len(data[data == zero])+1)/(len(data)+2)\n",
    "        data = data[data > zero]\n",
    "        if len(data) != 0: # O.W. we will use default in pdmf\n",
    "            # power law MLE\n",
    "            x_min = min(data)\n",
    "            shape = 1 + len(data)/(np.sum(np.log(data/x_min)))\n",
    "\n",
    "    elif dist == 'binomial' or dist == 'bernoulli': # MLE for Binomial or Bernoulli\n",
    "        #if not np.issubdtype(data, np.integer):\n",
    "        #    logging.warn(\"Can't calculate MLE. Not integer values for Binomial distribution.\")\n",
    "        #else:\n",
    "        if min(data) < zero:\n",
    "            logging.warn(wanringMsg.format(\"x < \" + str(zero)))\n",
    "            data = data[data >= zero]\n",
    "        p0 = (len(data[data == zero]) + 1)/(len(data) + 2)\n",
    "        \n",
    "    return {'loc':loc, 'scale':scale, 'shape':shape, 'xmin':x_min, 'p0':p0, 'logp0':np.log(p0), 'cnt':cnt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nCr\n",
    "import operator as op\n",
    "def ncr(nn, rr):\n",
    "    pdb.set_trace()\n",
    "    rr = min(rr, nn-rr)\n",
    "    if rr == 0: return 1\n",
    "    numer = reduce(op.mul, xrange(nn, nn-rr, -1))\n",
    "    denom = reduce(op.mul, xrange(1, rr+1))\n",
    "    return numer//denom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pdf or pmf \n",
    "Results of out-of-sample data based for the theoretical distribution given its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pdmf(data, dist, params, default, zero = 0):\n",
    "    # IMPORTANT: we assume data is sorted in ascending order\n",
    "    loc = params['loc']\n",
    "    scale = params['scale']\n",
    "    shape = params['shape']\n",
    "    p0 = params['p0']\n",
    "    x_min = params['xmin']\n",
    "    cnt = params['cnt']\n",
    "    \n",
    "    if loc == -1 and scale == -1 and shape == -1:\n",
    "        loc, scale, shape, x_min = use_default(dist, default)\n",
    "    \n",
    "    ll = None\n",
    "    warningMsg = \"Data out of range for \" + dist + \". Will remove \"\n",
    "    \n",
    "    if dist == 'norm': # pdf for Normal\n",
    "        pdmf_arr = np.exp(-(data-loc)**2/(2*scale**2))/(scale * np.sqrt(2*np.pi))\n",
    "\n",
    "    elif dist == 'lognorm': # pdf for Log-normal\n",
    "        if min(data) <= 0:\n",
    "            logging.warn(warningMsg+\"x <= 0\")\n",
    "            data = data[data > 0]\n",
    "        lndata = np.log(data)\n",
    "        pdmf_arr = np.exp(-(lndata-loc)**2/(2*scale**2))/(data*scale*np.sqrt(2*np.pi))\n",
    "    \n",
    "    elif dist == 'powerlaw': # pdf for Power Law\n",
    "        if min(data) <= 0:\n",
    "            logging.warn(warningMsg+\"x <= 0\")\n",
    "            data = data[data > 0]\n",
    "        # x_min is just set to the smallest non-zero x\n",
    "        #x_min = min(data)\n",
    "        pdmf_arr = (shape-1)*(data/x_min)**(-shape)/x_min\n",
    "    \n",
    "    elif dist == 'zin_norm': # pdf for Zero-Inflated Normal\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        zero_count = len(data[data == zero])\n",
    "        data = data[data > zero] # nonzero data\n",
    "        pdmf_arr = np.exp(-(data-loc)**2/(2*scale**2))/(scale * np.sqrt(2*np.pi))\n",
    "        pdmf_arr = np.append([p0]*zero_count, (1 - p0)*pdmf_arr) # data was sorted in ascending order\n",
    "\n",
    "    elif dist == 'zin_lognorm': # pmf for Zero-Inflated Log-normal\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        zero_count = len(data[data == zero])\n",
    "        data = data[data > zero] # nonzero data\n",
    "        lndata = np.log(data)\n",
    "        pdmf_arr = np.exp(-(lndata-loc)**2/(2*scale**2))/(data*scale*np.sqrt(2*np.pi))\n",
    "        pdmf_arr = np.append([p0]*zero_count, (1 - p0)*pdmf_arr) # data was sorted in ascending order\n",
    "        \n",
    "    elif dist == 'zin_powerlaw': # pmf for Zero-Inflated Power Law\n",
    "        if min(data) < 0:\n",
    "            logging.warn(warningMsg+\"x < 0\")\n",
    "        zero_count = len(data[data == zero])\n",
    "        data = data[data > zero]\n",
    "        #x_min = min(data)\n",
    "        pdmf_arr = (shape-1)*(data/x_min)**(-shape)/x_min\n",
    "        pdmf_arr = np.append([p0]*zero_count, (1 - p0)*pdmf_arr) # data was sorted in ascending order\n",
    "        \n",
    "    elif dist == 'binomial': # pmf for Binomial\n",
    "        #if not all(item.is_integer() for item in data):\n",
    "        #if not issubclass(data.dtype, np.integer):\n",
    "        #    logging.warn(\"Can't calculate MLE. Not integer values for Binomial distribution.\")\n",
    "        #else:\n",
    "        if min(data) < 0:\n",
    "            logging.warn(wanringMsg+\"x < 0\")\n",
    "            data = data[data >= zero]\n",
    "        pdmf_arr = []\n",
    "        hh = ss.binom(cnt, p0)\n",
    "        for d in data.tolist():\n",
    "            #pdmf_arr += [ncr(cnt, d)*p0**(cnt-d)*(1-p0)**d]\n",
    "            pdmf_arr += hh.pmf(d)\n",
    "        pdmf_arr = np.asarray(pdmf_arr)\n",
    "    elif dist == 'bernoulli': # pmf for Bernoulli\n",
    "        #if not all(item.is_integer() for item in data):\n",
    "        #    logging.warn(\"Can't calculate MLE. Not integer values for Bernoulli distribution.\")\n",
    "        #else:\n",
    "        if min(data) < 0:\n",
    "            logging.warn(wanringMsg+\"x < 0\")\n",
    "            data = data[data >= zero]\n",
    "        pdmf_arr = []\n",
    "        for d in data.tolist():\n",
    "            pdmf_arr += [p0 if d == 0 else (1-p0)]\n",
    "        pdmf_arr = np.asarray(pdmf_arr)\n",
    "    return pdmf_arr\n",
    "\n",
    "def llhood(data, dist, params, zero = 0):\n",
    "    pdmf_arr = pdmf(data, dist, params, zero)\n",
    "    ll = np.sum(np.log(pdmf_arr))    \n",
    "    return ll\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF or PMF\n",
    "## For a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singleval_pdmf(val, dist, params, default, zero = 0):\n",
    "    # IMPORTANT: we assume data is sorted in ascending order\n",
    "    loc = params['loc']\n",
    "    scale = params['scale']\n",
    "    shape = params['shape']\n",
    "    p0 = params['p0']\n",
    "    x_min = params['xmin']\n",
    "    cnt = params['cnt']\n",
    "    \n",
    "    if loc == -1 and scale == -1 and shape == -1:\n",
    "        loc, scale, shape, x_min = use_default(dist, default)\n",
    "    \n",
    "    ll = None\n",
    "    res = -1\n",
    "    warningMsg = \"Data out of range for \" + dist + \". Will return -1 \"\n",
    "    \n",
    "    if dist == 'norm': # pdf for Normal\n",
    "        res = np.exp(-(val-loc)**2/(2*scale**2))/(scale * np.sqrt(2*np.pi))\n",
    "\n",
    "    elif dist == 'lognorm': # pdf for Log-normal\n",
    "        if val <= 0: logging.warn(warningMsg+\"x <= 0\")\n",
    "        else: res = np.exp(-(np.log(val)-loc)**2/(2*scale**2))/(val*scale*np.sqrt(2*np.pi))\n",
    "    \n",
    "    elif dist == 'powerlaw': # pdf for Power Law\n",
    "        if val <= 0: logging.warn(warningMsg+\"x <= 0\")\n",
    "        else: res = (shape-1)*(val/x_min)**(-shape)/x_min\n",
    "    \n",
    "    elif dist == 'zin_norm': # pdf for Zero-Inflated Normal\n",
    "        if val < 0: logging.warn(warningMsg+\"x < 0\")\n",
    "        else:\n",
    "            if val == zero: res = p0\n",
    "            else: res = np.exp(-(val-loc)**2/(2*scale**2))/(scale * np.sqrt(2*np.pi))\n",
    "\n",
    "    elif dist == 'zin_lognorm': # pmf for Zero-Inflated Log-normal\n",
    "        if val < 0: logging.warn(warningMsg+\"x < 0\")\n",
    "        else:\n",
    "            if val == zero: res = p0\n",
    "            else: res = np.exp(-(np.log(val)-loc)**2/(2*scale**2))/(val*scale*np.sqrt(2*np.pi))\n",
    "        \n",
    "    elif dist == 'zin_powerlaw': # pmf for Zero-Inflated Power Law\n",
    "        if val < 0: logging.warn(warningMsg+\"x < 0\")\n",
    "        else:\n",
    "            if val == zero: res = p0\n",
    "            else: res = (shape-1)*(val/x_min)**(-shape)/x_min\n",
    "        \n",
    "    elif dist == 'binomial': # pmf for Binomial\n",
    "        #if not all(item.is_integer() for item in data):\n",
    "        #if not issubclass(data.dtype, np.integer):\n",
    "        #    logging.warn(\"Can't calculate MLE. Not integer values for Binomial distribution.\")\n",
    "        #else:\n",
    "        pdb.set_trace()\n",
    "        if val < 0: logging.warn(wanringMsg+\"x < 0\")\n",
    "        else: res = ncr(cnt, val)*p0**(cnt-val)*(1-p0)**val\n",
    "    elif dist == 'bernoulli': # pmf for Bernoulli\n",
    "        #if not all(item.is_integer() for item in data):\n",
    "        #    logging.warn(\"Can't calculate MLE. Not integer values for Bernoulli distribution.\")\n",
    "        #else:\n",
    "        if val < 0: logging.warn(wanringMsg+\"x < 0\")\n",
    "        else: res = p0 if val == 0 else (1-p0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Fit Distribution\n",
    "## Function name: best_fit_distribution\n",
    "**Args:**\n",
    "* data -> a series of data values (like group norms in our case)\n",
    "* bins -> how many bins we want to divide the data into (default = 200)\n",
    "* ax -> axes subplots (default None)\n",
    "  * subplot of the data with x and y limits set\n",
    "  * If given, this function will add histogram of data + all different distribution lines to this subplot\n",
    "\n",
    "**Returns:**\n",
    "* Best_Distribution_name -> winner among all distributions\n",
    "* Best_SSE -> Minimum sum of squared error\n",
    "* Best_params -> parameters of the best distribution which has at least two parameters of \"Location\" and \"Scale\" + any additional parameters based on the distribution type\n",
    "\n",
    "**What it does?**\n",
    "* Creates a histogram of the data divided to <BINS> bins\n",
    "* Sets x as the center of each bin\n",
    "* Sets y as the frequency value of each bin (normed = True)\n",
    "* Finds the best fit distribution among previously defined distributions based on the SSE of the returned value and the actual value\n",
    "  * Uses scipy.stats distribution methods **fit** and **pdf**\n",
    "  * scipy.stats current Distributions are **norm**, **expon**, and **lognorm** for now\n",
    "* If ax is set, it adds histogram and all the distributions lines with their MLE parameters to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create models from data\n",
    "def best_fit_distribution(train, test, ax=None, zero=0):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    DISTRIBUTIONS = [\n",
    "        'norm', 'lognorm', 'powerlaw', 'zin_lognorm', 'zin_powerlaw'\n",
    "    ]\n",
    "    # Best holders\n",
    "    best_distribution = ss.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_ll = -1 * np.inf\n",
    "\n",
    "    dist_ll = {}\n",
    "    \n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            params = mle(train, distribution, zero)\n",
    "            ll = llhood(test, distribution, params, zero)\n",
    "\n",
    "            dist_ll[distribution] = [round(ll, 2), params]\n",
    "    \n",
    "            # identify if this distribution is better\n",
    "            if best_ll < ll:\n",
    "                best_distribution = distribution\n",
    "                best_params = params\n",
    "                best_ll = ll\n",
    "        except Exception as detail:\n",
    "            print('Runtime Error: ' + str(detail))\n",
    "            pass\n",
    "                \n",
    "        if ax:\n",
    "             # Calculate fitted PDF and error with fit in distribution\n",
    "            y = pdmf(test, distribution, params, zero)\n",
    "            pd.Series(y, test). \\\n",
    "            plot(ax=ax, label=distribution + str(round(ll, 2)))\n",
    "\n",
    "    return (best_distribution, best_ll, best_params, dist_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test \n",
    "\n",
    "Will be commented for the sake of not being imported in other notebooks.\n",
    "Whenever you want to try the codes in this notebook, you can comment it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#data = ss.lognorm.rvs(1,size=100)\n",
    "#data = np.sort(data)\n",
    "#data = np.append(data , [0] * 5)\n",
    "#data = data + 0.00000001\n",
    "val_idx = plt.hist(data, bins=105, normed=1, color='grey')\n",
    "idx = val_idx[1]\n",
    "params = mle(data + 0.1, 'lognorm', 0)\n",
    "#params1 = mle(data+0.000001, 'lognorm', 0)\n",
    "params2 = ss.lognorm.fit(data)\n",
    "print params\n",
    "print params2\n",
    "#print params1\n",
    "ll = llhood(data + 0.1, 'lognorm', params, 0)\n",
    "idx = (idx[1:] + idx[:-1])/2\n",
    "pdmf_arr = pdmf(idx + 0.1, 'lognorm', params, 0)\n",
    "pdf = ss.lognorm.pdf(idx, loc=params2[-2], scale=params2[-1], *params2[:-2])\n",
    "#pdb.set_trace()\n",
    "plt.plot(idx, pdmf_arr, color='green')\n",
    "#plt.plot(idx, pdf, color='red')\n",
    "plt.title('ll: ' + str(ll))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
